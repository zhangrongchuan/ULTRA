import os
from typing import List, Optional

import torch
from torch import Tensor

from sentence_transformers import SentenceTransformer

from relbench.datasets import get_dataset
from relbench.modeling.utils import get_stype_proposal
from relbench.modeling.graph import make_pkey_fkey_graph
from torch_frame.config.text_embedder import TextEmbedderConfig

#å¯¼å…¥æ•°æ®å¹¶ä¸”æ‹¿åˆ°å¯¹åº”çš„å›¾æ•°æ®
# ==== 1. Load data ====
dataset = get_dataset("rel-f1", download=True)
db = dataset.get_db()

# ==== 2. get all the table and table info====
col_to_stype_dict = get_stype_proposal(db)

# ==== 3.define a text embedding model====
class GloveTextEmbedding:
    def __init__(self, device: Optional[torch.device] = None):
        self.model = SentenceTransformer(
            "sentence-transformers/average_word_embeddings_glove.6B.300d",
            device=device,
        )

    def __call__(self, sentences: List[str]) -> Tensor:
        # return shape [num_sent, emb_dim]--torch.Tensor
        return torch.from_numpy(self.model.encode(sentences))

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
text_embedder_cfg = TextEmbedderConfig(
    text_embedder=GloveTextEmbedding(device=device),
    batch_size=256,
)

# ==== 4. construct pk to fk graph====
root_dir = "./relbench_cache"
os.makedirs(root_dir, exist_ok=True)

data, col_stats_dict = make_pkey_fkey_graph(
    db,
    col_to_stype_dict=col_to_stype_dict,
    text_embedder_cfg=text_embedder_cfg,
    cache_dir=os.path.join(root_dir, "rel-f1_materialized_cache"),
)

# ==== ğŸš€ åˆ é™¤æ‰€æœ‰ reverse å…³ç³» ====
reverse_edge_types = [
    etype for etype in data.edge_types
    if etype[1].startswith("rev_")
]

for etype in reverse_edge_types:
    # print("Removing reverse relation:", etype)
    del data[etype]

print("\nRemoved:", len(reverse_edge_types), "reverse relations\n")

# ==== 5. Print graph info ====
print("\n=== Graph info ===")
print("node typeï¼š", data.node_types)
print(len(data.node_types))
print("edge typeï¼š", data.edge_types)
print(len(data.edge_types))

for ntype in data.node_types:
    print(f"{ntype}: num_nodes = {data[ntype].num_nodes}")

for etype in data.edge_types:
    ei = data[etype].edge_index
    print(f"{etype}: edge_index shape = {ei.shape}")
    
    
###ç”Ÿæˆä¸‰å…ƒç»„åˆ—è¡¨ (s, r, o)###
# ====== 6. ç»™æ¯ä¸ª node åˆ†é…å…¨å±€å®ä½“ ID ======
node_offsets = {}
current = 0
for ntype in data.node_types:
    num = data[ntype].num_nodes
    node_offsets[ntype] = current
    current += num

print("node_offsets:", node_offsets)

# ====== 7. ç»™æ¯ä¸€ç§ edge type åˆ†é…å…³ç³» ID ======
rel2id = {}          # (src_type, rel_name, dst_type) -> rel_id
relid2info = {}      # rel_id -> {src_type, rel_name, dst_type}
next_rel_id = 0
all_quads = []       # å­˜æ‰€æœ‰ (s, r, o)

for etype in data.edge_types:
    src_type, rel_name, dst_type = etype

    # ä¿è¯æ¯ä¸€ç§ (src, rel, dst) å¯¹åº”å”¯ä¸€çš„å…³ç³» ID
    if etype not in rel2id:
        rel2id[etype] = next_rel_id
        relid2info[next_rel_id] = {
            "src_type": src_type,
            "rel_name": rel_name,
            "dst_type": dst_type,
        }
        next_rel_id += 1

    r_id = rel2id[etype]

    # å½“å‰ edge type çš„æ‰€æœ‰è¾¹
    edge_index = data[etype].edge_index  # [2, num_edges]
    src_local = edge_index[0]            # [num_edges]
    dst_local = edge_index[1]

    # è½¬æˆå…¨å±€å®ä½“ ID
    src_global = src_local + node_offsets[src_type]
    dst_global = dst_local + node_offsets[dst_type]

    # ç”Ÿæˆ (s, r, o) triple
    triples_for_etype = torch.stack(
        [src_global, torch.full_like(src_global, r_id), dst_global],
        dim=-1  # [num_edges, 3]
    )
    all_quads.append(triples_for_etype)

# æ‹¼æˆä¸€ä¸ªå¤§çš„ [E_total, 3] tensor
all_quads = torch.cat(all_quads, dim=0)

print("\n=== Triple list (sample) ===")
print(all_quads[:50])
print("Total number of edges :", all_quads.shape[0])
print("Total num of relations:", len(rel2id))

from saved2local import *
# ä¿å­˜entityæ˜ å°„åˆ°æœ¬åœ°
save_entity_mapping(db, data, node_offsets, "./entities.tsv")
# ä¿å­˜å…³ç³»æ˜ å°„åˆ°æœ¬åœ°
save_relation_mapping(relid2info, "./relations.tsv")
# ä¿å­˜ä¸‰å…ƒç»„åˆ°æœ¬åœ°
save_all_triples(all_quads, path="./graph.txt")

if False:##if link prediction task, then do the following data split
    ###æ•°æ®åˆ†å‰²å’Œè¿‡æ»¤
    # all_quads: [E_total, 3]  (s, r, o)
    triples = all_quads.clone()

    # 1. æ‰“ä¹±é¡ºåº
    perm = torch.randperm(triples.shape[0])
    triples = triples[perm]

    # 2. ç²—ç•¥æŒ‰æ¯”ä¾‹åˆ‡ 80% / 10% / 10%
    n_total = triples.shape[0]
    n_train = int(n_total * 0.8)
    n_valid = int(n_total * 0.1)

    train = triples[:n_train]
    valid = triples[n_train:n_train + n_valid]
    test  = triples[n_train + n_valid:]


    def get_entities_and_relations(triples_tensor: torch.Tensor):
        """ä» [N,3] çš„ (s,r,o) tensor é‡Œæå–å®ä½“é›†åˆå’Œå…³ç³»é›†åˆ"""
        s = triples_tensor[:, 0]
        r = triples_tensor[:, 1]
        o = triples_tensor[:, 2]
        entities = set(s.tolist()) | set(o.tolist())
        relations = set(r.tolist())
        return entities, relations


    # 3. ç¡®ä¿ valid/test ä¸­çš„ å®ä½“ / å…³ç³»ç±»å‹ éƒ½åœ¨ train é‡Œå‡ºç°
    train_ents, train_rels = get_entities_and_relations(train)

    def filter_split(split, train_ents, train_rels):
        """æŠŠ split é‡Œä¸æ»¡è¶³(å®ä½“/å…³ç³»å·²åœ¨ train å‡ºç°) çš„æ ·æœ¬ç§»å› train"""
        keep = []
        move_to_train = []
        for t in split:
            s, r, o = t.tolist()
            if (s in train_ents) and (o in train_ents) and (r in train_rels):
                keep.append(t)
            else:
                move_to_train.append(t)
        if keep:
            keep = torch.stack(keep)
        else:
            keep = torch.empty((0, 3), dtype=split.dtype)
        if move_to_train:
            move_to_train = torch.stack(move_to_train)
        else:
            move_to_train = torch.empty((0, 3), dtype=split.dtype)
        return keep, move_to_train

    # å…ˆå¤„ç† valid
    valid, back_to_train = filter_split(valid, train_ents, train_rels)
    if back_to_train.shape[0] > 0:
        train = torch.cat([train, back_to_train], dim=0)
        train_ents, train_rels = get_entities_and_relations(train)

    # å†å¤„ç† test
    test, back_to_train = filter_split(test, train_ents, train_rels)
    if back_to_train.shape[0] > 0:
        train = torch.cat([train, back_to_train], dim=0)
        train_ents, train_rels = get_entities_and_relations(train)

    print("Final sizes:")
    print("train:", train.shape[0])
    print("valid:", valid.shape[0])
    print("test :", test.shape[0])
    
    def save_triples(tensor, path):
        with open(path, "w") as f:
            for s, r, o in tensor.tolist():
                f.write(f"{s}\t{r}\t{o}\n")

    save_triples(train, "train.txt")
    save_triples(valid, "valid.txt")
    save_triples(test,  "test.txt")
    print("Saved train/valid/test triples.")
    
